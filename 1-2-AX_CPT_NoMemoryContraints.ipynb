{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import numpy as np\n",
    "import random\n",
    "import hrr\n",
    "import math\n",
    "from plotly.graph_objs import Scatter, Layout, Surface\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transform(error):\n",
    "    return math.copysign(1.0,error)*math.log(math.fabs(error)+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(arr,t=1.0):\n",
    "    w = np.array(arr)\n",
    "    e = np.exp(w / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(arr_2d,restrict):\n",
    "    max_row = restrict[0]\n",
    "    max_col = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_2d[restrict[0],0]\n",
    "    for row in range(arr_2d.shape[0]):\n",
    "        if row not in restrict:\n",
    "            continue\n",
    "        for col in range(arr_2d.shape[1]):\n",
    "            if arr_2d[row,col] > max_value:\n",
    "                max_value = arr_2d[row,col]\n",
    "                max_row,max_col = row,col\n",
    "    return list((max_row,max_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax1(arr_3d,outer,inner):\n",
    "    max_row = outer[0]\n",
    "    max_col = inner[0]\n",
    "    max_x = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_3d[outer[0],inner[0],0]\n",
    "    for row in range(arr_3d.shape[0]):\n",
    "        if row not in outer:\n",
    "            continue\n",
    "        for col in range(arr_3d.shape[1]):\n",
    "            if col not in inner:\n",
    "                continue\n",
    "            for x in range(arr_3d.shape[2]):\n",
    "                if arr_3d[row,col,x] > max_value:\n",
    "                    max_value = arr_3d[row,col,x]\n",
    "                    max_row,max_col,max_x = row,col,x\n",
    "    return list((max_row,max_col,max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def context_check(outer,inner):\n",
    "    if outer == 0:\n",
    "        if inner == 0:\n",
    "            return 'AX'\n",
    "        elif inner == 1:\n",
    "            return 'AY'\n",
    "    elif outer == 1:\n",
    "        if inner == 0:\n",
    "            return 'BX'\n",
    "        elif inner == 1:\n",
    "            return 'BY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(outer,inner,action,cont,arr_2d):\n",
    "    # arr_2d[count,numcorrect,performance]\n",
    "    if context_check(outer,inner)=='AX':\n",
    "        #count1+=1\n",
    "        arr_2d[0,0]+=1\n",
    "        if action == 0 and cont == 0 or action == 1 and cont == 1:\n",
    "            #nc1 += 1\n",
    "            arr_2d[0,1]+=1\n",
    "        #AX_perf = nc1/count1\n",
    "        arr_2d[0,2] = arr_2d[0,1]/arr_2d[0,0]\n",
    "    elif context_check(outer,inner)=='BX':\n",
    "        #count2+=1\n",
    "        arr_2d[1,0]+=1\n",
    "        if action == 1:\n",
    "            #nc2 += 1\n",
    "            arr_2d[1,1]+=1\n",
    "        #BX_perf = nc2/count2\n",
    "        arr_2d[1,2] = arr_2d[1,1]/arr_2d[1,0]\n",
    "    elif context_check(outer,inner)=='AY':\n",
    "        #count3+=1\n",
    "        arr_2d[2,0]+=1\n",
    "        if action == 1:\n",
    "            #nc3 += 1\n",
    "            arr_2d[2,1]+=1\n",
    "        #AY_perf = nc3/count3\n",
    "        arr_2d[2,2] = arr_2d[2,1]/arr_2d[2,0]\n",
    "    elif context_check(outer,inner)=='BY':\n",
    "        #count4+=1\n",
    "        arr_2d[3,0]+=1\n",
    "        if action == 1 and cont == 0 or action == 0 and cont == 1:\n",
    "            #nc4 += 1\n",
    "            arr_2d[3,1]+=1\n",
    "        #BY_perf = nc4/count4\n",
    "        arr_2d[3,2] = arr_2d[3,1]/arr_2d[3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TD(ntrials,lrate,gamma,td_lambda,temp,decay,time):\n",
    "    n = 2024\n",
    "    nactions = 2 # number of actions\n",
    "    nouter_wm = 2 # number of context wm\n",
    "    ninner_wm = 2 # number of inner wm slots\n",
    "    n_context = 2 # number of context signals\n",
    "    n_cue = 2 # number of cue signals\n",
    "    n_probe = 2 # number of probe signals\n",
    "    n_cue_probe = 4\n",
    "    \n",
    "    ######## reward functions ##########\n",
    "    # reward matix, reward given at 0,0,0\n",
    "    # A-X target context\n",
    "    # 0 action => right press, 1 action => left press\n",
    "    reward1 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward1[0,0,0] = 1\n",
    "    reward1[0,1,1] = 1\n",
    "    reward1[1,0,1] = 1\n",
    "    reward1[1,1,1] = 1\n",
    "    # B-Y target context\n",
    "    reward2 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward2[0,0,1] = 1\n",
    "    reward2[0,1,1] = 1\n",
    "    reward2[1,0,1] = 1\n",
    "    reward2[1,1,0] = 1\n",
    "    # press left reward\n",
    "    reward3 = [0,0.2]\n",
    "    ####################################\n",
    "    \n",
    "    \n",
    "    ############## hrrs ###############\n",
    "    # identity vector\n",
    "    hrr_i = np.zeros(n)\n",
    "    hrr_i[0] = 1\n",
    "    \n",
    "    # L R actions hrr\n",
    "    actions = hrr.hrrs(n,nactions)\n",
    "    \n",
    "    # 1 2 context signal hrr\n",
    "    context_signal = hrr.hrrs(n,n_context)\n",
    "    context_signal = np.row_stack((context_signal,hrr_i))\n",
    "    \n",
    "    # cue signal hrr # not used\n",
    "    cue_signal = hrr.hrrs(n,n_cue)\n",
    "    cue_signal = np.row_stack((cue_signal,hrr_i))\n",
    "    \n",
    "    # probe signal hrr # not used\n",
    "    probe_signal = hrr.hrrs(n,n_probe)\n",
    "    probe_signal = np.row_stack((probe_signal,hrr_i))\n",
    "    \n",
    "    # cue and probe signals hrr\n",
    "    #cue_probe_signal = hrr.hrrs(n,n_cue_probe)\n",
    "    #cue_probe_signal = np.row_stack((cue_probe_signal,hrr_i))\n",
    "    \n",
    "    # outer working memory hrr\n",
    "    outer_wm = hrr.hrrs(n,nouter_wm)\n",
    "    outer_wm = np.row_stack((outer_wm,hrr_i))\n",
    "    \n",
    "    # inner working memory hrr\n",
    "    inner_wm = hrr.hrrs(n,ninner_wm)\n",
    "    inner_wm = np.row_stack((inner_wm,hrr_i))\n",
    "    \n",
    "    # precomputed hrr\n",
    "    #context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    #context_action_outerwm = np.reshape(context_action_outerwm,(n_context+1,nouter_wm+1,nactions,n))\n",
    "    \n",
    "    #signal_action_innerwm = hrr.oconvolve(actions,hrr.oconvolve(cue_probe_signal,inner_wm))\n",
    "    #signal_action_innerwm = np.reshape(signal_action_innerwm,(n_cue_probe+1,ninner_wm+1,nactions,n))\n",
    "    ########################################\n",
    "    context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    signal_innerwm = hrr.oconvolve(cue_signal,hrr.oconvolve(inner_wm,probe_signal))\n",
    "    computed = hrr.oconvolve(context_action_outerwm,signal_innerwm)\n",
    "    computed = np.reshape(computed,(n_context+1,n_cue+1,n_probe+1,nouter_wm+1,ninner_wm+1,nactions,n))\n",
    "    \n",
    "    # weight vector and bias\n",
    "    W = hrr.hrr(n)\n",
    "    bias = 1\n",
    "    \n",
    "    # epsilon soft\n",
    "    epsilon = .01\n",
    "    \n",
    "    # temperatue for softmax\n",
    "    t = temp\n",
    "    \n",
    "    nsteps = 200\n",
    "    context = 2 # init context\n",
    "    \n",
    "    perf_arr = np.zeros((4,3))\n",
    "    \n",
    "    # lists used for displaying performance graph\n",
    "    AX_data_pts = []\n",
    "    BX_data_pts = []\n",
    "    AY_data_pts = []\n",
    "    BY_data_pts = []\n",
    "    \n",
    "    for trial in range(1,ntrials+1):\n",
    "        if trial%50 == 0:\n",
    "            eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            error = r - value\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "               \n",
    "        context = np.random.choice([0,1],p=[.5,.5]) # choose context signal\n",
    "        \n",
    "        if context == 0:\n",
    "            reward = reward1 # use reward function 1\n",
    "        elif context == 1:\n",
    "            reward = reward2 # use reward function 2\n",
    "            \n",
    "        cue,probe = 2,2 # init with no cue/probe signal\n",
    "        current_inner_wm = 2 # init with nothing in wm\n",
    "        current_outer_wm = 2 # init with nothing in wm\n",
    "        \n",
    "        values = np.dot(computed[context,cue,probe,:,current_inner_wm,:,:],W) + bias\n",
    "        #print(values.shape)\n",
    "        sm_prob = softmax(values,t)\n",
    "        #possible_wm = np.unique(np.array([context]))\n",
    "        possible_wm = np.unique(np.array([context,0,1,2])) # no constraints on memory\n",
    "        \n",
    "        wm_action = argmax(sm_prob,possible_wm)\n",
    "        current_outer_wm = wm_action[0]\n",
    "        action = wm_action[1]\n",
    "        #print('ContexWM:',current_outer_wm)\n",
    "        #print(context,current_outer_wm,action)\n",
    "        # epsilon goes here\n",
    "        if random.random() < epsilon:\n",
    "            current_outer_wm = random.randint(0,nouter_wm)\n",
    "            action = random.randrange(nactions)\n",
    "            \n",
    "        value = values[current_outer_wm,action]\n",
    "        eligibility = np.zeros(n)\n",
    "        global_context = context # used for reward function\n",
    "        \n",
    "        \n",
    "        \n",
    "        for step in range(nsteps):\n",
    "            r = reward3[action] # # reward function, may not be needed\n",
    "            \n",
    "            # absorb reward\n",
    "            #if trial%50 == 0:\n",
    "            #    eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            #    error = r - value\n",
    "            #    W += lrate*log_transform(error)*eligibility\n",
    "            #    break\n",
    "            \n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = random.randint(0,1) # get cue signal\n",
    "            global_cue = cue # used for reward function\n",
    "            probe = 2\n",
    "            context = 2\n",
    "            \n",
    "            values = np.dot(computed[context,cue,probe,current_outer_wm,:,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            #possible_wm = np.unique(np.array([2,cue]))\n",
    "            possible_wm = np.unique(np.array([cue,0,1,2])) # no memory constraints\n",
    "            \n",
    "            wm_action = argmax(sm_prob,possible_wm)\n",
    "            current_inner_wm = wm_action[0]\n",
    "            action = wm_action[1]\n",
    "            # epsilon goes here\n",
    "            if random.random() < epsilon:\n",
    "                current_inner_wm = random.randint(0,ninner_wm) \n",
    "                action = random.randrange(nactions)\n",
    "            \n",
    "            value = values[current_inner_wm,action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            \n",
    "            ###########################################\n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = 2\n",
    "            probe = random.randint(0,1) # get probe signal\n",
    "            context = 2\n",
    "            global_probe = probe # used for reward function\n",
    "            \n",
    "            values = np.dot(computed[context,cue,probe,current_outer_wm,current_inner_wm,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            #possible_wm = np.unique(np.array([2,signal]))\n",
    "            #wm_action = argmax(sm_prob,possible_wm)\n",
    "            #current_inner_wm = wm_action[0]\n",
    "            #action = wm_action[1]\n",
    "            action = np.argmax(sm_prob)\n",
    "            # epsilon goes here\n",
    "            if random.random() < epsilon:\n",
    "                action = random.randrange(nactions)\n",
    "            \n",
    "            #value = values[current_inner_wm,action]\n",
    "            r = reward[global_cue,global_probe,action]\n",
    "            value = values[action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            #print(global_context,global_cue,global_probe,action,'reward:',r)\n",
    "            \n",
    "            \n",
    "            performance(global_cue,global_probe,action,global_context,perf_arr)\n",
    "            \n",
    "            #print(AX_data_pts)\n",
    "        ########################################\n",
    "        #print(context,cue,probe,action)\n",
    "        if trial%1000==0:\n",
    "            print('Trial:',trial,end='\\n\\n')\n",
    "            print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "            print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "            print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "            print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "            print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "            \n",
    "            AX_data_pts.append(perf_arr[0,2])\n",
    "            BX_data_pts.append(perf_arr[1,2])\n",
    "            AY_data_pts.append(perf_arr[2,2])\n",
    "            BY_data_pts.append(perf_arr[3,2])\n",
    "            \n",
    "            perf_arr = np.zeros((4,3))\n",
    "            print(end='\\n\\n')\n",
    "        \n",
    "    print('Trial:',trial,end='\\n\\n')\n",
    "    print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "    print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "    print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "    print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "    print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "\n",
    "    print(end='\\n\\n')\n",
    "    \n",
    "    V1,V2,V3,V4 = AX_data_pts,BX_data_pts,AY_data_pts,BY_data_pts\n",
    "    \n",
    "    plotly.offline.iplot([\n",
    "            dict(x=[x for x in range(len(V1))] , y=V1, type='scatter',name='AX'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V2, type='scatter',name='BX'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V3, type='scatter',name='AY'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V4, type='scatter',name='BY')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1000\n",
      "\n",
      "                  count          performance\n",
      "AX |            49927.0               75.50%\n",
      "BX |            50224.0               90.66%\n",
      "AY |            50093.0               91.93%\n",
      "BY |            49756.0               72.13%\n",
      "\n",
      "\n",
      "Trial: 2000\n",
      "\n",
      "                  count          performance\n",
      "AX |            50100.0               73.52%\n",
      "BX |            49853.0               91.50%\n",
      "AY |            49989.0               93.52%\n",
      "BY |            50058.0               70.27%\n",
      "\n",
      "\n",
      "Trial: 3000\n",
      "\n",
      "                  count          performance\n",
      "AX |            50085.0               76.39%\n",
      "BX |            49932.0               91.42%\n",
      "AY |            49901.0               92.39%\n",
      "BY |            50082.0               72.82%\n",
      "\n",
      "\n",
      "Trial: 4000\n",
      "\n",
      "                  count          performance\n",
      "AX |            49801.0               76.42%\n",
      "BX |            50041.0               92.12%\n",
      "AY |            50081.0               93.64%\n",
      "BY |            50077.0               72.75%\n",
      "\n",
      "\n",
      "Trial: 5000\n",
      "\n",
      "                  count          performance\n",
      "AX |            50073.0               93.33%\n",
      "BX |            49959.0               96.29%\n",
      "AY |            49960.0               96.72%\n",
      "BY |            50008.0               87.72%\n",
      "\n",
      "\n",
      "Trial: 6000\n",
      "\n",
      "                  count          performance\n",
      "AX |            50092.0               87.82%\n",
      "BX |            50261.0               95.02%\n",
      "AY |            49994.0               95.36%\n",
      "BY |            49653.0               84.17%\n",
      "\n",
      "\n",
      "Trial: 7000\n",
      "\n",
      "                  count          performance\n",
      "AX |            49898.0               94.46%\n",
      "BX |            50309.0               96.24%\n",
      "AY |            49727.0               96.06%\n",
      "BY |            50066.0               89.28%\n",
      "\n",
      "\n",
      "Trial: 8000\n",
      "\n",
      "                  count          performance\n",
      "AX |            49942.0               94.54%\n",
      "BX |            50089.0               96.72%\n",
      "AY |            49856.0               96.89%\n",
      "BY |            50113.0               91.96%\n",
      "\n",
      "\n",
      "Trial: 9000\n",
      "\n",
      "                  count          performance\n",
      "AX |            49751.0               92.71%\n",
      "BX |            50048.0               96.75%\n",
      "AY |            50148.0               96.99%\n",
      "BY |            50053.0               92.55%\n",
      "\n",
      "\n",
      "Trial: 10000\n",
      "\n",
      "                  count          performance\n",
      "AX |            49900.0               94.56%\n",
      "BX |            50105.0               96.53%\n",
      "AY |            49638.0               96.85%\n",
      "BY |            50357.0               86.59%\n",
      "\n",
      "\n",
      "Trial: 10000\n",
      "\n",
      "                  count          performance\n",
      "AX |                0.0                0.00%\n",
      "BX |                0.0                0.00%\n",
      "AY |                0.0                0.00%\n",
      "BY |                0.0                0.00%\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "AX",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.7549822741202156,
          0.7352095808383233,
          0.7638614355595488,
          0.7642416818939378,
          0.9332774149741377,
          0.8781641779126408,
          0.9446270391598862,
          0.9454367065796324,
          0.9270768426765291,
          0.9456312625250501
         ]
        },
        {
         "name": "BX",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.9065984389933099,
          0.9149900708081761,
          0.9141632620363694,
          0.9212245958314182,
          0.9628895694469465,
          0.9502198523706253,
          0.9623924148760659,
          0.9672383157978798,
          0.967511189258312,
          0.9652729268536074
         ]
        },
        {
         "name": "AY",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.919310083245164,
          0.9351657364620216,
          0.9239494198513056,
          0.9363830594437011,
          0.9672337870296237,
          0.9535744289314718,
          0.9606049027691194,
          0.9688703465982028,
          0.9699290101300152,
          0.9684717353640356
         ]
        },
        {
         "name": "BY",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.7213200418040036,
          0.7027248391865436,
          0.7282456770895731,
          0.7274796812908122,
          0.877199648056311,
          0.8417215475399271,
          0.8928214756521392,
          0.9196216550595654,
          0.9254789922681957,
          0.8658974919077784
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"1b9e8f06-aebd-4485-a7e8-8bfaabb94935\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1b9e8f06-aebd-4485-a7e8-8bfaabb94935\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.7549822741202156, 0.7352095808383233, 0.7638614355595488, 0.7642416818939378, 0.9332774149741377, 0.8781641779126408, 0.9446270391598862, 0.9454367065796324, 0.9270768426765291, 0.9456312625250501], \"type\": \"scatter\", \"name\": \"AX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.9065984389933099, 0.9149900708081761, 0.9141632620363694, 0.9212245958314182, 0.9628895694469465, 0.9502198523706253, 0.9623924148760659, 0.9672383157978798, 0.967511189258312, 0.9652729268536074], \"type\": \"scatter\", \"name\": \"BX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.919310083245164, 0.9351657364620216, 0.9239494198513056, 0.9363830594437011, 0.9672337870296237, 0.9535744289314718, 0.9606049027691194, 0.9688703465982028, 0.9699290101300152, 0.9684717353640356], \"type\": \"scatter\", \"name\": \"AY\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.7213200418040036, 0.7027248391865436, 0.7282456770895731, 0.7274796812908122, 0.877199648056311, 0.8417215475399271, 0.8928214756521392, 0.9196216550595654, 0.9254789922681957, 0.8658974919077784], \"type\": \"scatter\", \"name\": \"BY\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"1b9e8f06-aebd-4485-a7e8-8bfaabb94935\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1b9e8f06-aebd-4485-a7e8-8bfaabb94935\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.7549822741202156, 0.7352095808383233, 0.7638614355595488, 0.7642416818939378, 0.9332774149741377, 0.8781641779126408, 0.9446270391598862, 0.9454367065796324, 0.9270768426765291, 0.9456312625250501], \"type\": \"scatter\", \"name\": \"AX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.9065984389933099, 0.9149900708081761, 0.9141632620363694, 0.9212245958314182, 0.9628895694469465, 0.9502198523706253, 0.9623924148760659, 0.9672383157978798, 0.967511189258312, 0.9652729268536074], \"type\": \"scatter\", \"name\": \"BX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.919310083245164, 0.9351657364620216, 0.9239494198513056, 0.9363830594437011, 0.9672337870296237, 0.9535744289314718, 0.9606049027691194, 0.9688703465982028, 0.9699290101300152, 0.9684717353640356], \"type\": \"scatter\", \"name\": \"AY\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.7213200418040036, 0.7027248391865436, 0.7282456770895731, 0.7274796812908122, 0.877199648056311, 0.8417215475399271, 0.8928214756521392, 0.9196216550595654, 0.9254789922681957, 0.8658974919077784], \"type\": \"scatter\", \"name\": \"BY\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TD(10000,.4,.9,.8,.1,0,0)\n",
    "# (num trials, learning rate, discount factor, lambda, temperature, decay factor, decay time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
