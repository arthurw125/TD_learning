{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import numpy as np\n",
    "import random\n",
    "import hrr\n",
    "import math\n",
    "from plotly.graph_objs import Scatter, Layout, Surface\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transform(error):\n",
    "    return math.copysign(1.0,error)*math.log(math.fabs(error)+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(arr,t=1.0):\n",
    "    w = np.array(arr)\n",
    "    e = np.exp(w / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(arr_3d,outer,inner):\n",
    "    max_row = outer[0]\n",
    "    max_col = inner[0]\n",
    "    max_x = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_3d[outer[0],inner[0],0]\n",
    "    for row in range(arr_3d.shape[0]):\n",
    "        if row not in outer:\n",
    "            continue\n",
    "        for col in range(arr_3d.shape[1]):\n",
    "            if col not in inner:\n",
    "                continue\n",
    "            for x in range(arr_3d.shape[2]):\n",
    "                if arr_3d[row,col,x] > max_value:\n",
    "                    max_value = arr_3d[row,col,x]\n",
    "                    max_row,max_col,max_x = row,col,x\n",
    "    return list((max_row,max_col,max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def context_check(outer,inner):\n",
    "    if outer == 0:\n",
    "        if inner == 0:\n",
    "            return 'AX'\n",
    "        elif inner == 1:\n",
    "            return 'AY'\n",
    "    elif outer == 1:\n",
    "        if inner == 0:\n",
    "            return 'BX'\n",
    "        elif inner == 1:\n",
    "            return 'BY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(outer,inner,action,cont,arr_2d):\n",
    "    # arr_2d[count,numcorrect,performance]\n",
    "    if context_check(outer,inner)=='AX':\n",
    "        #count1+=1\n",
    "        arr_2d[0,0]+=1\n",
    "        if action == 0 and cont == 0 or action == 1 and cont == 1:\n",
    "            #nc1 += 1\n",
    "            arr_2d[0,1]+=1\n",
    "        #AX_perf = nc1/count1\n",
    "        arr_2d[0,2] = arr_2d[0,1]/arr_2d[0,0]\n",
    "    elif context_check(outer,inner)=='BX':\n",
    "        #count2+=1\n",
    "        arr_2d[1,0]+=1\n",
    "        if action == 1:\n",
    "            #nc2 += 1\n",
    "            arr_2d[1,1]+=1\n",
    "        #BX_perf = nc2/count2\n",
    "        arr_2d[1,2] = arr_2d[1,1]/arr_2d[1,0]\n",
    "    elif context_check(outer,inner)=='AY':\n",
    "        #count3+=1\n",
    "        arr_2d[2,0]+=1\n",
    "        if action == 1:\n",
    "            #nc3 += 1\n",
    "            arr_2d[2,1]+=1\n",
    "        #AY_perf = nc3/count3\n",
    "        arr_2d[2,2] = arr_2d[2,1]/arr_2d[2,0]\n",
    "    elif context_check(outer,inner)=='BY':\n",
    "        #count4+=1\n",
    "        arr_2d[3,0]+=1\n",
    "        if action == 1 and cont == 0 or action == 0 and cont == 1:\n",
    "            #nc4 += 1\n",
    "            arr_2d[3,1]+=1\n",
    "        #BY_perf = nc4/count4\n",
    "        arr_2d[3,2] = arr_2d[3,1]/arr_2d[3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TD(ntrials,lrate,gamma,td_lambda,temp,decay,time):\n",
    "    n = 1024\n",
    "    nactions = 2 # number of actions\n",
    "    ncont_wm = 2 # number of context wm\n",
    "    nwm_o = 2 # number of outer wm slots\n",
    "    nwm_i = 2 # number of inner wm slots\n",
    "    nsig_o = 2 # number of cue signals\n",
    "    nsig_i = 2 # number of probe signals\n",
    "    ncont_o = 2 # number of context signals\n",
    "    \n",
    "    # reward matix, reward given at 0,0,0\n",
    "    # A-X target context\n",
    "    \n",
    "    reward1 = np.zeros((nsig_o+1,nsig_i+1,nactions))\n",
    "    reward1[0,0,0] = 1\n",
    "    reward1[0,1,1] = 1\n",
    "    reward1[1,0,1] = 1\n",
    "    reward1[1,1,1] = 1\n",
    "    # B-Y target context\n",
    "    reward2 = np.zeros((nsig_o+1,nsig_i+1,nactions))\n",
    "    reward2[0,0,1] = 1\n",
    "    reward2[0,1,1] = 1\n",
    "    reward2[1,0,1] = 1\n",
    "    reward2[1,1,0] = 1\n",
    "    \n",
    "    \"\"\"\n",
    "    reward = np.zeros((ncont_o+1,nsig_o+1,nsig_i+1,nactions))\n",
    "    reward[0,0,0,0] = 1\n",
    "    reward[0,0,1,1] = 1\n",
    "    reward[0,1,0,1] = 1\n",
    "    reward[0,1,1,1] = 1\n",
    "    \n",
    "    reward[1,0,0,1] = 1\n",
    "    reward[1,0,1,1] = 1\n",
    "    reward[1,1,0,1] = 1\n",
    "    reward[1,1,1,0] = 1\n",
    "    \"\"\"\n",
    "    #reward_outer = np.zeros((nsig_o+1,nactions))\n",
    "    #reward_outer[0,0] = 1\n",
    "    #reward_outer[1,1] = 1\n",
    "    # hrr for actions\n",
    "    actions = hrr.hrrs(n,nactions)\n",
    "    \n",
    "    # identity vector\n",
    "    hrr_i = np.zeros(n)\n",
    "    hrr_i[0] = 1\n",
    "    \n",
    "    # context outer cue\n",
    "    cont_outer = hrr.hrrs(n,ncont_o)\n",
    "    cont_outer = np.row_stack((cont_outer,hrr_i))\n",
    "    \n",
    "    # cue outer\n",
    "    sig_outer = hrr.hrrs(n,nsig_o)\n",
    "    sig_outer = np.row_stack((sig_outer,hrr_i))\n",
    "    \n",
    "    # probe inner\n",
    "    sig_inner = hrr.hrrs(n,nsig_i)\n",
    "    sig_inner = np.row_stack((sig_inner,hrr_i))\n",
    "     \n",
    "    # context working memory\n",
    "    wm_cont = hrr.hrrs(n,ncont_wm)\n",
    "    wm_cont = np.row_stack((wm_cont,hrr_i))\n",
    "        \n",
    "    # outer working memory\n",
    "    wm_outer = hrr.hrrs(n,nwm_o)\n",
    "    wm_outer = np.row_stack((wm_outer,hrr_i))\n",
    "    \n",
    "    # inner working memory\n",
    "    wm_inner = hrr.hrrs(n,nwm_i)\n",
    "    wm_inner = np.row_stack((wm_inner,hrr_i))\n",
    "    \n",
    "    # precomputed\n",
    "    external = hrr.oconvolve(sig_inner,sig_outer) \n",
    "    s_a = hrr.oconvolve(external,actions)\n",
    "    s_a = np.reshape(s_a,(nsig_o+1,nsig_i+1,nactions,n))\n",
    "    # weight vector and bias\n",
    "    W = hrr.hrr(n)\n",
    "    bias = 1\n",
    "    \n",
    "    # epsilon for e-soft policy\n",
    "    epsilon = .01\n",
    "    \n",
    "    # temperature for softmax\n",
    "    t = temp\n",
    "    \n",
    "    # eligibility trace\n",
    "    eligibility = np.zeros(n)\n",
    "    # array that keeps track of AX-CPT performance\n",
    "    perf_arr = np.zeros((4,3))\n",
    "    context = 0\n",
    "    for trial in range(ntrials):\n",
    "        r = 0\n",
    "        eligibility = np.zeros(n)\n",
    "        # 70% AX trials, 30% AY,BX,BY trials #\n",
    "        index = np.random.choice([0,1,2,3],p=[.25,.25,.25,.25])\n",
    "        choices = [(0,0),(0,1),(1,0),(1,1)]\n",
    "        cue,probe = choices[index]\n",
    "        #################################\n",
    "        if trial%200==0:\n",
    "            context = np.random.choice([0,1],p=[.5,.5])\n",
    "        #context = 0\n",
    "            \n",
    "        if context == 0:\n",
    "            reward = reward1 # updates reward policy for A-X target\n",
    "        elif context == 1:\n",
    "            reward = reward2 # updates reward policy for B-Y target\n",
    "        # sets context for later use\n",
    "    \n",
    "        outer = cue\n",
    "        \n",
    "        inner = probe\n",
    "        \n",
    "        ####### stage 1\n",
    "        cont_outerwm = hrr.convolve(cont_outer[context], wm_cont)\n",
    "        values = np.dot(cont_outerwm,W) + bias\n",
    "        possible_context = np.unique([context])\n",
    "        \n",
    "        sm_prob = softmax(values,t)\n",
    "        #print(sm_prob)\n",
    "        wm_o = np.unravel_index(np.argmax(np.take(sm_prob,possible_context)),sm_prob.shape)\n",
    "        wm_o = possible_context[wm_o]\n",
    "        \n",
    "        trace1 = hrr.convolve(sig_outer[context],wm_cont[wm_o])\n",
    "        wm1 = wm_cont[wm_o]\n",
    "        \n",
    "        pvalues = values[wm_o] # stores previous Q value\n",
    "        eligibility = cont_outerwm[wm_o] + td_lambda*eligibility\n",
    "        ##### end stage 1\n",
    "        \n",
    "        \n",
    "        ###### is cue worth remembering #######\n",
    "        #######################################\n",
    "        cue_outerwm = hrr.convolve(sig_outer[cue],wm_outer)\n",
    "        values = np.dot(cue_outerwm,W) + bias\n",
    "        possible_context = np.unique([cue,2])\n",
    "        \n",
    "        sm_prob = softmax(values,t)\n",
    "        wm_o = np.unravel_index(np.argmax(np.take(sm_prob,possible_context)),sm_prob.shape)\n",
    "        wm_o = possible_context[wm_o]\n",
    "        #wm1 = wm_outer[wm_o] # selected memory slot\n",
    "        #print('convolve:',cue_outerwm.shape)\n",
    "        #print('values:',values.shape)\n",
    "        #print('smax:',sm_prob.shape)\n",
    "        #print('wm1:',wm1.shape)\n",
    "        #print(wm_o)\n",
    "        #print(sm_prob)\n",
    "        value = values[wm_o]\n",
    "        ########## epsilon soft ##################\n",
    "        if random.random() < epsilon:\n",
    "            wm_o = random.randrange(nwm_o+1)\n",
    "            \n",
    "        #error = (r+gamma*value)-pvalues\n",
    "        #W += lrate*log_transform(error)*eligibility\n",
    "        \n",
    "        trace1 = hrr.convolve(sig_outer[cue],wm_outer[wm_o])\n",
    "        wm1 = wm_outer[wm_o] # selected memory slot\n",
    "        ###### decay chosen workingMemory ########\n",
    "        wm_outer_decayed = np.array(wm1)\n",
    "        wm_outer_decayed = hrr.pow(wm_outer_decayed,decay**time)\n",
    "        #trace1 = hrr.convolve(sig_outer[cue],wm_outer_decayed) #changed\n",
    "        #######################################\n",
    "        \n",
    "        #r = 0 # reward for outer memory choice\n",
    "        pvalue = values[wm_o] # stores previous Q value\n",
    "        eligibility = cue_outerwm[wm_o] + td_lambda*eligibility\n",
    "        #eligibility = trace1 + td_lambda*eligibility\n",
    "        #######################################\n",
    "        wm1_wm2 = hrr.convolve(wm_outer_decayed,wm_inner) # convolve chosen outer wm with matrix of inner wm choices\n",
    "        #wm1_wm2 = hrr.convolve(trace1,wm_inner) # changed\n",
    "        probe_outerinnerwm_a = hrr.convolve(sig_inner[probe],hrr.oconvolve(wm1_wm2,actions))\n",
    "        probe_outerinnerwm_a = np.reshape(probe_outerinnerwm_a,(nwm_o+1,nactions,n))\n",
    "        values = np.dot(probe_outerinnerwm_a,W) + bias\n",
    "        possible_context = np.unique([probe,2])\n",
    "        \n",
    "        sm_prob = softmax(values,t)\n",
    "        wm_i = np.unravel_index(np.argmax(sm_prob),sm_prob.shape) \n",
    "        current_memory = wm_i[0]\n",
    "        action = wm_i[1]\n",
    "        \n",
    "        #print('probe:',probe_outerinnerwm_a.shape)\n",
    "        #print('value:',values.shape)\n",
    "        #print('smax:',sm_prob.shape)\n",
    "        #print(sm_prob)\n",
    "        #print(eligibility.shape)\n",
    "        #######################################\n",
    "    \n",
    "        ######### epsilon soft policy ##########\n",
    "        if random.random() < epsilon:\n",
    "            \n",
    "            action = random.randrange(0,nactions)\n",
    "            current_memory = random.randrange(nwm_i+1)\n",
    "            #current_outer_wm = random.randrange(nwm_o+1)\n",
    "            #current_inner_wm = random.randrange(nwm_i+1)\n",
    "        ########################################  \n",
    "        r = reward[outer,inner,action]\n",
    "        #print(outer,inner,action,\"\\t\",r)\n",
    "        value = values[current_memory,action]\n",
    "        error = (r + gamma*value) - pvalue\n",
    "        W += lrate*log_transform(error)*eligibility\n",
    "        \n",
    "        eligibility = probe_outerinnerwm_a[current_memory,action,:] + td_lambda*eligibility\n",
    "        ########################################\n",
    "        value = values[current_memory,action]\n",
    "        #r = reward[outer,inner,action]\n",
    "        error = r - value\n",
    "        W += lrate*log_transform(error)*eligibility\n",
    "        performance(outer,inner,action,context,perf_arr)\n",
    "        ########################################\n",
    "        #print(context,cue,probe,action)\n",
    "        if trial%1000==0:\n",
    "            print('Trial:',trial,end='\\n\\n')\n",
    "            print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "            print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "            print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "            print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "            print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "            perf_arr = np.zeros((4,3))\n",
    "            print(end='\\n\\n')\n",
    "        \n",
    "    print('Trial:',trial,end='\\n\\n')\n",
    "    print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "    print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "    print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "    print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "    print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "    perf_arr = np.zeros((4,3))\n",
    "    print(end='\\n\\n')\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "\n",
      "                  count          performance\n",
      "AX |                1.0                0.00%\n",
      "BX |                0.0                0.00%\n",
      "AY |                0.0                0.00%\n",
      "BY |                0.0                0.00%\n",
      "\n",
      "\n",
      "Trial: 1000\n",
      "\n",
      "                  count          performance\n",
      "AX |              247.0               94.74%\n",
      "BX |              260.0               98.08%\n",
      "AY |              260.0               97.31%\n",
      "BY |              233.0               95.28%\n",
      "\n",
      "\n",
      "Trial: 2000\n",
      "\n",
      "                  count          performance\n",
      "AX |              256.0               96.88%\n",
      "BX |              257.0               99.22%\n",
      "AY |              231.0               98.27%\n",
      "BY |              256.0               94.14%\n",
      "\n",
      "\n",
      "Trial: 3000\n",
      "\n",
      "                  count          performance\n",
      "AX |              258.0               98.84%\n",
      "BX |              235.0               99.15%\n",
      "AY |              256.0               98.44%\n",
      "BY |              251.0               96.02%\n",
      "\n",
      "\n",
      "Trial: 4000\n",
      "\n",
      "                  count          performance\n",
      "AX |              224.0               98.21%\n",
      "BX |              256.0               99.22%\n",
      "AY |              266.0               99.62%\n",
      "BY |              254.0               95.28%\n",
      "\n",
      "\n",
      "Trial: 5000\n",
      "\n",
      "                  count          performance\n",
      "AX |              243.0               94.65%\n",
      "BX |              245.0               99.59%\n",
      "AY |              252.0               98.02%\n",
      "BY |              260.0               93.46%\n",
      "\n",
      "\n",
      "Trial: 6000\n",
      "\n",
      "                  count          performance\n",
      "AX |              236.0               94.92%\n",
      "BX |              268.0               99.63%\n",
      "AY |              255.0              100.00%\n",
      "BY |              241.0               87.14%\n",
      "\n",
      "\n",
      "Trial: 7000\n",
      "\n",
      "                  count          performance\n",
      "AX |              229.0               93.45%\n",
      "BX |              255.0               92.55%\n",
      "AY |              252.0               99.21%\n",
      "BY |              264.0               95.83%\n",
      "\n",
      "\n",
      "Trial: 8000\n",
      "\n",
      "                  count          performance\n",
      "AX |              253.0               98.02%\n",
      "BX |              263.0               98.86%\n",
      "AY |              246.0               99.59%\n",
      "BY |              238.0               97.06%\n",
      "\n",
      "\n",
      "Trial: 9000\n",
      "\n",
      "                  count          performance\n",
      "AX |              241.0               95.02%\n",
      "BX |              277.0               99.28%\n",
      "AY |              222.0               99.10%\n",
      "BY |              260.0               95.00%\n",
      "\n",
      "\n",
      "Trial: 10000\n",
      "\n",
      "                  count          performance\n",
      "AX |              255.0               98.82%\n",
      "BX |              253.0              100.00%\n",
      "AY |              243.0               98.77%\n",
      "BY |              249.0               93.57%\n",
      "\n",
      "\n",
      "Trial: 11000\n",
      "\n",
      "                  count          performance\n",
      "AX |              241.0               96.68%\n",
      "BX |              264.0              100.00%\n",
      "AY |              250.0               99.60%\n",
      "BY |              245.0               93.06%\n",
      "\n",
      "\n",
      "Trial: 12000\n",
      "\n",
      "                  count          performance\n",
      "AX |              239.0               95.40%\n",
      "BX |              245.0              100.00%\n",
      "AY |              257.0               99.61%\n",
      "BY |              259.0               86.49%\n",
      "\n",
      "\n",
      "Trial: 13000\n",
      "\n",
      "                  count          performance\n",
      "AX |              245.0               93.47%\n",
      "BX |              249.0              100.00%\n",
      "AY |              280.0               99.29%\n",
      "BY |              226.0               90.71%\n",
      "\n",
      "\n",
      "Trial: 14000\n",
      "\n",
      "                  count          performance\n",
      "AX |              246.0               94.72%\n",
      "BX |              245.0              100.00%\n",
      "AY |              268.0              100.00%\n",
      "BY |              241.0               94.19%\n",
      "\n",
      "\n",
      "Trial: 15000\n",
      "\n",
      "                  count          performance\n",
      "AX |              262.0               96.56%\n",
      "BX |              234.0               99.15%\n",
      "AY |              244.0              100.00%\n",
      "BY |              260.0               91.54%\n",
      "\n",
      "\n",
      "Trial: 16000\n",
      "\n",
      "                  count          performance\n",
      "AX |              225.0               92.00%\n",
      "BX |              238.0               99.16%\n",
      "AY |              277.0               98.92%\n",
      "BY |              260.0               83.85%\n",
      "\n",
      "\n",
      "Trial: 17000\n",
      "\n",
      "                  count          performance\n",
      "AX |              230.0               95.22%\n",
      "BX |              225.0               99.56%\n",
      "AY |              268.0               99.63%\n",
      "BY |              277.0               95.67%\n",
      "\n",
      "\n",
      "Trial: 18000\n",
      "\n",
      "                  count          performance\n",
      "AX |              230.0               89.57%\n",
      "BX |              268.0               99.25%\n",
      "AY |              243.0               98.77%\n",
      "BY |              259.0               88.03%\n",
      "\n",
      "\n",
      "Trial: 19000\n",
      "\n",
      "                  count          performance\n",
      "AX |              236.0               94.07%\n",
      "BX |              259.0               99.61%\n",
      "AY |              254.0               99.61%\n",
      "BY |              251.0               75.70%\n",
      "\n",
      "\n",
      "Trial: 19999\n",
      "\n",
      "                  count          performance\n",
      "AX |              244.0               88.93%\n",
      "BX |              254.0               96.46%\n",
      "AY |              253.0               98.02%\n",
      "BY |              248.0               54.84%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TD(20000,.1,.9,.8,.1,0,0)\n",
    "# (num trials, learning rate, discount factor, lambda, temperature, decay factor, decay time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "print(x[None,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.take(x,[0,2]))\n",
    "#mask = [True,True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(x>2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            count          performance\n",
      "AX |                           12           45.000000%\n",
      "AY |                           12           45.000000%\n",
      "BX |                           12           45.000000%\n",
      "BY |                           12           45.000000%\n"
     ]
    }
   ],
   "source": [
    "count = 12\n",
    "perf = .45\n",
    "print(format('','>20s'),format('count','>12s'),format('performance','>20s'))\n",
    "print(format('AX |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('AY |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('BX |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('BY |','<20s'),format(count,'>12d'),format(perf,'>20%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
