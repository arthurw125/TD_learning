{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import numpy as np\n",
    "import random\n",
    "import hrr\n",
    "import math\n",
    "from plotly.graph_objs import Scatter, Layout, Surface\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transform(error):\n",
    "    return math.copysign(1.0,error)*math.log(math.fabs(error)+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(arr,t=1.0):\n",
    "    w = np.array(arr)\n",
    "    e = np.exp(w / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(arr_2d,restrict):\n",
    "    max_row = restrict[0]\n",
    "    max_col = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_2d[restrict[0],0]\n",
    "    for row in range(arr_2d.shape[0]):\n",
    "        if row not in restrict:\n",
    "            continue\n",
    "        for col in range(arr_2d.shape[1]):\n",
    "            if arr_2d[row,col] > max_value:\n",
    "                max_value = arr_2d[row,col]\n",
    "                max_row,max_col = row,col\n",
    "    return list((max_row,max_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax1(arr_3d,outer,inner):\n",
    "    max_row = outer[0]\n",
    "    max_col = inner[0]\n",
    "    max_x = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_3d[outer[0],inner[0],0]\n",
    "    for row in range(arr_3d.shape[0]):\n",
    "        if row not in outer:\n",
    "            continue\n",
    "        for col in range(arr_3d.shape[1]):\n",
    "            if col not in inner:\n",
    "                continue\n",
    "            for x in range(arr_3d.shape[2]):\n",
    "                if arr_3d[row,col,x] > max_value:\n",
    "                    max_value = arr_3d[row,col,x]\n",
    "                    max_row,max_col,max_x = row,col,x\n",
    "    return list((max_row,max_col,max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def context_check(outer,inner):\n",
    "    if outer == 0:\n",
    "        if inner == 0:\n",
    "            return 'AX'\n",
    "        elif inner == 1:\n",
    "            return 'AY'\n",
    "    elif outer == 1:\n",
    "        if inner == 0:\n",
    "            return 'BX'\n",
    "        elif inner == 1:\n",
    "            return 'BY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(outer,inner,action,cont,arr_2d):\n",
    "    # arr_2d[count,numcorrect,performance]\n",
    "    if context_check(outer,inner)=='AX':\n",
    "        #count1+=1\n",
    "        arr_2d[0,0]+=1\n",
    "        if action == 0 and cont == 0 or action == 1 and cont == 1:\n",
    "            #nc1 += 1\n",
    "            arr_2d[0,1]+=1\n",
    "        #AX_perf = nc1/count1\n",
    "        arr_2d[0,2] = arr_2d[0,1]/arr_2d[0,0]\n",
    "    elif context_check(outer,inner)=='BX':\n",
    "        #count2+=1\n",
    "        arr_2d[1,0]+=1\n",
    "        if action == 1:\n",
    "            #nc2 += 1\n",
    "            arr_2d[1,1]+=1\n",
    "        #BX_perf = nc2/count2\n",
    "        arr_2d[1,2] = arr_2d[1,1]/arr_2d[1,0]\n",
    "    elif context_check(outer,inner)=='AY':\n",
    "        #count3+=1\n",
    "        arr_2d[2,0]+=1\n",
    "        if action == 1:\n",
    "            #nc3 += 1\n",
    "            arr_2d[2,1]+=1\n",
    "        #AY_perf = nc3/count3\n",
    "        arr_2d[2,2] = arr_2d[2,1]/arr_2d[2,0]\n",
    "    elif context_check(outer,inner)=='BY':\n",
    "        #count4+=1\n",
    "        arr_2d[3,0]+=1\n",
    "        if action == 1 and cont == 0 or action == 0 and cont == 1:\n",
    "            #nc4 += 1\n",
    "            arr_2d[3,1]+=1\n",
    "        #BY_perf = nc4/count4\n",
    "        arr_2d[3,2] = arr_2d[3,1]/arr_2d[3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TD(ntrials,lrate,gamma,td_lambda,temp,decay,time):\n",
    "    n = 1024\n",
    "    nactions = 2 # number of actions\n",
    "    nouter_wm = 2 # number of context wm\n",
    "    ninner_wm = 2 # number of inner wm slots\n",
    "    n_context = 2 # number of context signals\n",
    "    n_cue = 2 # number of cue signals\n",
    "    n_probe = 2 # number of probe signals\n",
    "    n_cue_probe = 4\n",
    "    \n",
    "    ######## reward functions ##########\n",
    "    # reward matix, reward given at 0,0,0\n",
    "    # A-X target context\n",
    "    # 0 action => right press, 1 action => left press\n",
    "    reward1 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward1[0,0,0] = 1\n",
    "    reward1[0,1,1] = 1\n",
    "    reward1[1,0,1] = 1\n",
    "    reward1[1,1,1] = 1\n",
    "    # B-Y target context\n",
    "    reward2 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward2[0,0,1] = 1\n",
    "    reward2[0,1,1] = 1\n",
    "    reward2[1,0,1] = 1\n",
    "    reward2[1,1,0] = 1\n",
    "    # press left reward\n",
    "    reward3 = [0,0.2]\n",
    "    ####################################\n",
    "    \n",
    "    \n",
    "    ############## hrrs ###############\n",
    "    # identity vector\n",
    "    hrr_i = np.zeros(n)\n",
    "    hrr_i[0] = 1\n",
    "    \n",
    "    # L R actions hrr\n",
    "    actions = hrr.hrrs(n,nactions)\n",
    "    \n",
    "    # 1 2 context signal hrr\n",
    "    context_signal = hrr.hrrs(n,n_context)\n",
    "    context_signal = np.row_stack((context_signal,hrr_i))\n",
    "    \n",
    "    # cue signal hrr # not used\n",
    "    cue_signal = hrr.hrrs(n,n_cue)\n",
    "    cue_signal = np.row_stack((cue_signal,hrr_i))\n",
    "    \n",
    "    # probe signal hrr # not used\n",
    "    probe_signal = hrr.hrrs(n,n_probe)\n",
    "    probe_signal = np.row_stack((probe_signal,hrr_i))\n",
    "    \n",
    "    # cue and probe signals hrr\n",
    "    #cue_probe_signal = hrr.hrrs(n,n_cue_probe)\n",
    "    #cue_probe_signal = np.row_stack((cue_probe_signal,hrr_i))\n",
    "    \n",
    "    # outer working memory hrr\n",
    "    outer_wm = hrr.hrrs(n,nouter_wm)\n",
    "    outer_wm = np.row_stack((outer_wm,hrr_i))\n",
    "    \n",
    "    # inner working memory hrr\n",
    "    inner_wm = hrr.hrrs(n,ninner_wm)\n",
    "    inner_wm = np.row_stack((inner_wm,hrr_i))\n",
    "    \n",
    "    # precomputed hrr\n",
    "    #context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    #context_action_outerwm = np.reshape(context_action_outerwm,(n_context+1,nouter_wm+1,nactions,n))\n",
    "    \n",
    "    #signal_action_innerwm = hrr.oconvolve(actions,hrr.oconvolve(cue_probe_signal,inner_wm))\n",
    "    #signal_action_innerwm = np.reshape(signal_action_innerwm,(n_cue_probe+1,ninner_wm+1,nactions,n))\n",
    "    ########################################\n",
    "    context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    signal_innerwm = hrr.oconvolve(cue_signal,hrr.oconvolve(inner_wm,probe_signal))\n",
    "    computed = hrr.oconvolve(context_action_outerwm,signal_innerwm)\n",
    "    computed = np.reshape(computed,(n_context+1,n_cue+1,n_probe+1,nouter_wm+1,ninner_wm+1,nactions,n))\n",
    "    \n",
    "    # weight vector and bias\n",
    "    W = hrr.hrr(n)\n",
    "    bias = 1\n",
    "    \n",
    "    # epsilon soft\n",
    "    epsilon = .01\n",
    "    \n",
    "    # temperatue for softmax\n",
    "    t = temp\n",
    "    \n",
    "    nsteps = 100\n",
    "    context = 2 # init context\n",
    "    \n",
    "    perf_arr = np.zeros((4,3))\n",
    "    \n",
    "    # lists used for displaying performance graph\n",
    "    AX_data_pts = []\n",
    "    BX_data_pts = []\n",
    "    AY_data_pts = []\n",
    "    BY_data_pts = []\n",
    "    \n",
    "    for trial in range(ntrials):\n",
    "        \n",
    "        context = np.random.choice([0,1],p=[.5,.5]) # choose context signal\n",
    "        \n",
    "        if context == 0:\n",
    "            reward = reward1 # use reward function 1\n",
    "        elif context == 1:\n",
    "            reward = reward2 # use reward function 2\n",
    "            \n",
    "        cue,probe = 2,2 # init with no cue/probe signal\n",
    "        current_inner_wm = 2 # init with nothing in wm\n",
    "        current_outer_wm = 2 # init with nothing in wm\n",
    "        \n",
    "        values = np.dot(computed[context,cue,probe,:,current_inner_wm,:,:],W) + bias\n",
    "        #print(values.shape)\n",
    "        sm_prob = softmax(values,t)\n",
    "        possible_wm = np.unique(np.array([context]))\n",
    "        \n",
    "        wm_action = argmax(sm_prob,possible_wm)\n",
    "        current_outer_wm = wm_action[0]\n",
    "        action = wm_action[1]\n",
    "        #print('ContexWM:',current_outer_wm)\n",
    "        #print(context,current_outer_wm,action)\n",
    "        # epsilon goes here\n",
    "        if random.random() < epsilon:\n",
    "            current_outer_wm = random.randint(0,nouter_wm)\n",
    "            action = random.randrange(nactions)\n",
    "            \n",
    "        value = values[current_outer_wm,action]\n",
    "        eligibility = np.zeros(n)\n",
    "        global_context = context # used for reward function\n",
    "        \n",
    "        \n",
    "        \n",
    "        for step in range(nsteps):\n",
    "            r = reward3[action] # # reward function, may not be needed\n",
    "            \n",
    "            # absorb reward\n",
    "            if trial%50 == 0:\n",
    "                eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "                error = r - value\n",
    "                W += lrate*log_transform(error)*eligibility\n",
    "                break\n",
    "            \n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = random.randint(0,1) # get cue signal\n",
    "            global_cue = cue # used for reward function\n",
    "            probe = 2\n",
    "            context = 2\n",
    "            \n",
    "            values = np.dot(computed[context,cue,probe,current_outer_wm,:,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            possible_wm = np.unique(np.array([2,cue]))\n",
    "            wm_action = argmax(sm_prob,possible_wm)\n",
    "            current_inner_wm = wm_action[0]\n",
    "            action = wm_action[1]\n",
    "            # epsilon goes here\n",
    "            if random.random() < epsilon:\n",
    "                current_inner_wm = random.randint(0,ninner_wm) \n",
    "                action = random.randrange(nactions)\n",
    "            \n",
    "            value = values[current_inner_wm,action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            \n",
    "            ###########################################\n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = 2\n",
    "            probe = random.randint(0,1) # get probe signal\n",
    "            context = 2\n",
    "            global_probe = probe # used for reward function\n",
    "            \n",
    "            values = np.dot(computed[context,cue,probe,current_outer_wm,current_inner_wm,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            #possible_wm = np.unique(np.array([2,signal]))\n",
    "            #wm_action = argmax(sm_prob,possible_wm)\n",
    "            #current_inner_wm = wm_action[0]\n",
    "            #action = wm_action[1]\n",
    "            action = np.argmax(sm_prob)\n",
    "            # epsilon goes here\n",
    "            if random.random() < epsilon:\n",
    "                action = random.randrange(nactions)\n",
    "            \n",
    "            #value = values[current_inner_wm,action]\n",
    "            r = reward[global_cue,global_probe,action]\n",
    "            value = values[action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            #print(global_context,global_cue,global_probe,action,'reward:',r)\n",
    "            \n",
    "            \n",
    "            performance(global_cue,global_probe,action,global_context,perf_arr)\n",
    "            \n",
    "            #print(AX_data_pts)\n",
    "        ########################################\n",
    "        #print(context,cue,probe,action)\n",
    "        if trial%1000==0:\n",
    "            print('Trial:',trial,end='\\n\\n')\n",
    "            print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "            print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "            print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "            print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "            print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "            \n",
    "            AX_data_pts.append(perf_arr[0,2])\n",
    "            BX_data_pts.append(perf_arr[1,2])\n",
    "            AY_data_pts.append(perf_arr[2,2])\n",
    "            BY_data_pts.append(perf_arr[3,2])\n",
    "            \n",
    "            perf_arr = np.zeros((4,3))\n",
    "            print(end='\\n\\n')\n",
    "        \n",
    "    print('Trial:',trial,end='\\n\\n')\n",
    "    print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "    print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "    print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "    print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "    print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "\n",
    "    print(end='\\n\\n')\n",
    "    \n",
    "    V1,V2,V3,V4 = AX_data_pts,BX_data_pts,AY_data_pts,BY_data_pts\n",
    "    \n",
    "    plotly.offline.iplot([\n",
    "            dict(x=[x for x in range(len(V1))] , y=V1, type='scatter',name='AX'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V2, type='scatter',name='BX'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V3, type='scatter',name='AY'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V4, type='scatter',name='BY')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "\n",
      "                  count          performance\n",
      "AX |                0.0                0.00%\n",
      "BX |                0.0                0.00%\n",
      "AY |                0.0                0.00%\n",
      "BY |                0.0                0.00%\n",
      "\n",
      "\n",
      "Trial: 1000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24384.0               94.87%\n",
      "BX |            24659.0               94.46%\n",
      "AY |            24538.0               91.66%\n",
      "BY |            24419.0               90.09%\n",
      "\n",
      "\n",
      "Trial: 2000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24259.0               93.30%\n",
      "BX |            24361.0               95.30%\n",
      "AY |            24578.0               97.67%\n",
      "BY |            24802.0               92.68%\n",
      "\n",
      "\n",
      "Trial: 3000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24397.0               93.22%\n",
      "BX |            24554.0               95.85%\n",
      "AY |            24608.0               94.18%\n",
      "BY |            24441.0               89.89%\n",
      "\n",
      "\n",
      "Trial: 4000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24547.0               91.99%\n",
      "BX |            24445.0               95.04%\n",
      "AY |            24546.0               96.48%\n",
      "BY |            24462.0               91.00%\n",
      "\n",
      "\n",
      "Trial: 5000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24404.0               95.86%\n",
      "BX |            24529.0               96.91%\n",
      "AY |            24674.0               95.82%\n",
      "BY |            24393.0               92.37%\n",
      "\n",
      "\n",
      "Trial: 6000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24586.0               94.11%\n",
      "BX |            24502.0               95.89%\n",
      "AY |            24162.0               96.28%\n",
      "BY |            24750.0               92.49%\n",
      "\n",
      "\n",
      "Trial: 7000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24569.0               92.90%\n",
      "BX |            24414.0               94.43%\n",
      "AY |            24503.0               95.35%\n",
      "BY |            24514.0               90.60%\n",
      "\n",
      "\n",
      "Trial: 8000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24558.0               88.21%\n",
      "BX |            24583.0               95.07%\n",
      "AY |            24709.0               95.07%\n",
      "BY |            24150.0               91.39%\n",
      "\n",
      "\n",
      "Trial: 9000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24283.0               93.58%\n",
      "BX |            24710.0               95.98%\n",
      "AY |            24504.0               96.79%\n",
      "BY |            24503.0               90.87%\n",
      "\n",
      "\n",
      "Trial: 9999\n",
      "\n",
      "                  count          performance\n",
      "AX |            24388.0               93.57%\n",
      "BX |            24474.0               95.11%\n",
      "AY |            24418.0               94.59%\n",
      "BY |            24720.0               92.25%\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "AX",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0,
          0.94873687664042,
          0.932973329485964,
          0.9322047792761405,
          0.9199494846620768,
          0.9585723651860351,
          0.9410640201740829,
          0.9290162399772071,
          0.8820750875478459,
          0.9357987069143022
         ]
        },
        {
         "name": "BX",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0,
          0.9445638509266394,
          0.9529575961577932,
          0.9584589068990795,
          0.9504193086520761,
          0.9690978026010029,
          0.9589013141784344,
          0.9442532972884411,
          0.9506976365781231,
          0.9598138405503844
         ]
        },
        {
         "name": "AY",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0,
          0.9166191213627842,
          0.9766864675726259,
          0.9417669050715215,
          0.9647600423694288,
          0.9582151252330389,
          0.9627928151643076,
          0.9535158960127331,
          0.9507062204055202,
          0.9679236043095005
         ]
        },
        {
         "name": "BY",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0,
          0.9008558909046235,
          0.9268204177082493,
          0.8989403052248272,
          0.9100237102444608,
          0.9236666256712991,
          0.9249292929292929,
          0.9060128905931305,
          0.9139130434782609,
          0.9087050565236909
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"810e53bb-96f0-4cb6-9c55-abe44cc843c4\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"810e53bb-96f0-4cb6-9c55-abe44cc843c4\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.94873687664042, 0.932973329485964, 0.9322047792761405, 0.9199494846620768, 0.9585723651860351, 0.9410640201740829, 0.9290162399772071, 0.8820750875478459, 0.9357987069143022], \"type\": \"scatter\", \"name\": \"AX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.9445638509266394, 0.9529575961577932, 0.9584589068990795, 0.9504193086520761, 0.9690978026010029, 0.9589013141784344, 0.9442532972884411, 0.9506976365781231, 0.9598138405503844], \"type\": \"scatter\", \"name\": \"BX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.9166191213627842, 0.9766864675726259, 0.9417669050715215, 0.9647600423694288, 0.9582151252330389, 0.9627928151643076, 0.9535158960127331, 0.9507062204055202, 0.9679236043095005], \"type\": \"scatter\", \"name\": \"AY\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.9008558909046235, 0.9268204177082493, 0.8989403052248272, 0.9100237102444608, 0.9236666256712991, 0.9249292929292929, 0.9060128905931305, 0.9139130434782609, 0.9087050565236909], \"type\": \"scatter\", \"name\": \"BY\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"810e53bb-96f0-4cb6-9c55-abe44cc843c4\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"810e53bb-96f0-4cb6-9c55-abe44cc843c4\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.94873687664042, 0.932973329485964, 0.9322047792761405, 0.9199494846620768, 0.9585723651860351, 0.9410640201740829, 0.9290162399772071, 0.8820750875478459, 0.9357987069143022], \"type\": \"scatter\", \"name\": \"AX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.9445638509266394, 0.9529575961577932, 0.9584589068990795, 0.9504193086520761, 0.9690978026010029, 0.9589013141784344, 0.9442532972884411, 0.9506976365781231, 0.9598138405503844], \"type\": \"scatter\", \"name\": \"BX\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.9166191213627842, 0.9766864675726259, 0.9417669050715215, 0.9647600423694288, 0.9582151252330389, 0.9627928151643076, 0.9535158960127331, 0.9507062204055202, 0.9679236043095005], \"type\": \"scatter\", \"name\": \"AY\"}, {\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.0, 0.9008558909046235, 0.9268204177082493, 0.8989403052248272, 0.9100237102444608, 0.9236666256712991, 0.9249292929292929, 0.9060128905931305, 0.9139130434782609, 0.9087050565236909], \"type\": \"scatter\", \"name\": \"BY\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TD(10000,.4,.9,.8,.1,0,0)\n",
    "# (num trials, learning rate, discount factor, lambda, temperature, decay factor, decay time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "print(x[None,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.take(x,[0,2]))\n",
    "#mask = [True,True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(x>2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            count          performance\n",
      "AX |                           12           45.000000%\n",
      "AY |                           12           45.000000%\n",
      "BX |                           12           45.000000%\n",
      "BY |                           12           45.000000%\n"
     ]
    }
   ],
   "source": [
    "count = 12\n",
    "perf = .45\n",
    "print(format('','>20s'),format('count','>12s'),format('performance','>20s'))\n",
    "print(format('AX |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('AY |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('BX |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('BY |','<20s'),format(count,'>12d'),format(perf,'>20%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False False False False\n"
     ]
    }
   ],
   "source": [
    "reward(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
