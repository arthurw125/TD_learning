{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import numpy as np\n",
    "import random\n",
    "import hrr\n",
    "import math\n",
    "from plotly.graph_objs import Scatter, Layout, Surface\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transform(error):\n",
    "    return math.copysign(1.0,error)*math.log(math.fabs(error)+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(arr,t=1.0):\n",
    "    w = np.array(arr)\n",
    "    e = np.exp(w / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(arr_2d,restrict):\n",
    "    max_row = restrict[0]\n",
    "    max_col = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_2d[restrict[0],0]\n",
    "    for row in range(arr_2d.shape[0]):\n",
    "        if row not in restrict:\n",
    "            continue\n",
    "        for col in range(arr_2d.shape[1]):\n",
    "            if arr_2d[row,col] > max_value:\n",
    "                max_value = arr_2d[row,col]\n",
    "                max_row,max_col = row,col\n",
    "    return list((max_row,max_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax1(arr_3d,outer,inner):\n",
    "    max_row = outer[0]\n",
    "    max_col = inner[0]\n",
    "    max_x = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_3d[outer[0],inner[0],0]\n",
    "    for row in range(arr_3d.shape[0]):\n",
    "        if row not in outer:\n",
    "            continue\n",
    "        for col in range(arr_3d.shape[1]):\n",
    "            if col not in inner:\n",
    "                continue\n",
    "            for x in range(arr_3d.shape[2]):\n",
    "                if arr_3d[row,col,x] > max_value:\n",
    "                    max_value = arr_3d[row,col,x]\n",
    "                    max_row,max_col,max_x = row,col,x\n",
    "    return list((max_row,max_col,max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def context_check(outer,inner):\n",
    "    if outer == 0:\n",
    "        if inner == 0:\n",
    "            return 'AX'\n",
    "        elif inner == 1:\n",
    "            return 'AY'\n",
    "    elif outer == 1:\n",
    "        if inner == 0:\n",
    "            return 'BX'\n",
    "        elif inner == 1:\n",
    "            return 'BY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(outer,inner,action,cont,arr_2d):\n",
    "    # arr_2d[count,numcorrect,performance]\n",
    "    if context_check(outer,inner)=='AX':\n",
    "        #count1+=1\n",
    "        arr_2d[0,0]+=1\n",
    "        if action == 0 and cont == 0 or action == 1 and cont == 1:\n",
    "            #nc1 += 1\n",
    "            arr_2d[0,1]+=1\n",
    "        #AX_perf = nc1/count1\n",
    "        arr_2d[0,2] = arr_2d[0,1]/arr_2d[0,0]\n",
    "    elif context_check(outer,inner)=='BX':\n",
    "        #count2+=1\n",
    "        arr_2d[1,0]+=1\n",
    "        if action == 1:\n",
    "            #nc2 += 1\n",
    "            arr_2d[1,1]+=1\n",
    "        #BX_perf = nc2/count2\n",
    "        arr_2d[1,2] = arr_2d[1,1]/arr_2d[1,0]\n",
    "    elif context_check(outer,inner)=='AY':\n",
    "        #count3+=1\n",
    "        arr_2d[2,0]+=1\n",
    "        if action == 1:\n",
    "            #nc3 += 1\n",
    "            arr_2d[2,1]+=1\n",
    "        #AY_perf = nc3/count3\n",
    "        arr_2d[2,2] = arr_2d[2,1]/arr_2d[2,0]\n",
    "    elif context_check(outer,inner)=='BY':\n",
    "        #count4+=1\n",
    "        arr_2d[3,0]+=1\n",
    "        if action == 1 and cont == 0 or action == 0 and cont == 1:\n",
    "            #nc4 += 1\n",
    "            arr_2d[3,1]+=1\n",
    "        #BY_perf = nc4/count4\n",
    "        arr_2d[3,2] = arr_2d[3,1]/arr_2d[3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TD(ntrials,lrate,gamma,td_lambda,temp,decay,time):\n",
    "    n = 1024\n",
    "    nactions = 2 # number of actions\n",
    "    nouter_wm = 2 # number of context wm\n",
    "    ninner_wm = 2 # number of inner wm slots\n",
    "    n_context = 2 # number of context signals\n",
    "    n_cue = 2 # number of cue signals\n",
    "    n_probe = 2 # number of probe signals\n",
    "    n_cue_probe = 4\n",
    "    \n",
    "    ######## reward functions ##########\n",
    "    # reward matix, reward given at 0,0,0\n",
    "    # A-X target context\n",
    "    # 0 action => right press, 1 action => left press\n",
    "    reward1 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward1[0,0,0] = 1\n",
    "    reward1[0,1,1] = 1\n",
    "    reward1[1,0,1] = 1\n",
    "    reward1[1,1,1] = 1\n",
    "    # B-Y target context\n",
    "    reward2 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward2[0,0,1] = 1\n",
    "    reward2[0,1,1] = 1\n",
    "    reward2[1,0,1] = 1\n",
    "    reward2[1,1,0] = 1\n",
    "    # press left reward\n",
    "    reward3 = [0,0.2]\n",
    "    ####################################\n",
    "    \n",
    "    \n",
    "    ############## hrrs ###############\n",
    "    # identity vector\n",
    "    hrr_i = np.zeros(n)\n",
    "    hrr_i[0] = 1\n",
    "    \n",
    "    # L R actions hrr\n",
    "    actions = hrr.hrrs(n,nactions)\n",
    "    \n",
    "    # 1 2 context signal hrr\n",
    "    context_signal = hrr.hrrs(n,n_context)\n",
    "    context_signal = np.row_stack((context_signal,hrr_i))\n",
    "    \n",
    "    # cue signal hrr # not used\n",
    "    cue_signal = hrr.hrrs(n,n_cue)\n",
    "    cue_signal = np.row_stack((cue_signal,hrr_i))\n",
    "    \n",
    "    # probe signal hrr # not used\n",
    "    probe_signal = hrr.hrrs(n,n_probe)\n",
    "    probe_signal = np.row_stack((probe_signal,hrr_i))\n",
    "    \n",
    "    # cue and probe signals hrr\n",
    "    #cue_probe_signal = hrr.hrrs(n,n_cue_probe)\n",
    "    #cue_probe_signal = np.row_stack((cue_probe_signal,hrr_i))\n",
    "    \n",
    "    # outer working memory hrr\n",
    "    outer_wm = hrr.hrrs(n,nouter_wm)\n",
    "    outer_wm = np.row_stack((outer_wm,hrr_i))\n",
    "    \n",
    "    # inner working memory hrr\n",
    "    inner_wm = hrr.hrrs(n,ninner_wm)\n",
    "    inner_wm = np.row_stack((inner_wm,hrr_i))\n",
    "    \n",
    "    # precomputed hrr\n",
    "    #context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    #context_action_outerwm = np.reshape(context_action_outerwm,(n_context+1,nouter_wm+1,nactions,n))\n",
    "    \n",
    "    #signal_action_innerwm = hrr.oconvolve(actions,hrr.oconvolve(cue_probe_signal,inner_wm))\n",
    "    #signal_action_innerwm = np.reshape(signal_action_innerwm,(n_cue_probe+1,ninner_wm+1,nactions,n))\n",
    "    ########################################\n",
    "    context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    signal_innerwm = hrr.oconvolve(cue_signal,hrr.oconvolve(inner_wm,probe_signal))\n",
    "    computed = hrr.oconvolve(context_action_outerwm,signal_innerwm)\n",
    "    computed = np.reshape(computed,(n_context+1,n_cue+1,n_probe+1,nouter_wm+1,ninner_wm+1,nactions,n))\n",
    "    \n",
    "    # weight vector and bias\n",
    "    W = hrr.hrr(n)\n",
    "    bias = 1\n",
    "    \n",
    "    # epsilon soft\n",
    "    epsilon = .01\n",
    "    \n",
    "    # temperatue for softmax\n",
    "    t = temp\n",
    "    \n",
    "    nsteps = 100\n",
    "    context = 2 # init context\n",
    "    \n",
    "    perf_arr = np.zeros((4,3))\n",
    "    for trial in range(ntrials):\n",
    "        \n",
    "        context = np.random.choice([0,1],p=[.5,.5]) # choose context signal\n",
    "        \n",
    "        if context == 0:\n",
    "            reward = reward1 # use reward function 1\n",
    "        elif context == 1:\n",
    "            reward = reward2 # use reward function 2\n",
    "            \n",
    "        cue,probe = 2,2 # init with no cue/probe signal\n",
    "        current_inner_wm = 2 # init with nothing in wm\n",
    "        current_outer_wm = 2 # init with nothing in wm\n",
    "        \n",
    "        values = np.dot(computed[context,cue,probe,:,current_inner_wm,:,:],W) + bias\n",
    "        #print(values.shape)\n",
    "        sm_prob = softmax(values,t)\n",
    "        possible_wm = np.unique(np.array([context]))\n",
    "        \n",
    "        wm_action = argmax(sm_prob,possible_wm)\n",
    "        current_outer_wm = wm_action[0]\n",
    "        action = wm_action[1]\n",
    "        #print('ContexWM:',current_outer_wm)\n",
    "        #print(context,current_outer_wm,action)\n",
    "        # epsilon goes here\n",
    "        value = values[current_outer_wm,action]\n",
    "        eligibility = np.zeros(n)\n",
    "        global_context = context # used for reward function\n",
    "        for step in range(nsteps):\n",
    "            r = reward3[action] # # reward function, may not be needed\n",
    "            \n",
    "            if trial == 10:\n",
    "                eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "                error = r - value\n",
    "                W += lrate*log_transform(error)*eligibility\n",
    "                break\n",
    "            \n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = random.randint(0,1) # get cue signal\n",
    "            global_cue = cue # used for reward function\n",
    "            probe = 2\n",
    "            context = 2\n",
    "            \n",
    "            values = np.dot(computed[context,cue,probe,current_outer_wm,:,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            possible_wm = np.unique(np.array([2,cue]))\n",
    "            wm_action = argmax(sm_prob,possible_wm)\n",
    "            current_inner_wm = wm_action[0]\n",
    "            action = wm_action[1]\n",
    "            # epsilon goes here\n",
    "           \n",
    "            value = values[current_inner_wm,action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            \n",
    "            ###########################################\n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = 2\n",
    "            probe = random.randint(0,1) # get probe signal\n",
    "            context = 2\n",
    "            global_probe = probe # used for reward function\n",
    "            \n",
    "            values = np.dot(computed[context,cue,probe,current_outer_wm,current_inner_wm,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            #possible_wm = np.unique(np.array([2,signal]))\n",
    "            #wm_action = argmax(sm_prob,possible_wm)\n",
    "            #current_inner_wm = wm_action[0]\n",
    "            #action = wm_action[1]\n",
    "            action = np.argmax(sm_prob)\n",
    "            # epsilon goes here\n",
    "            #value = values[current_inner_wm,action]\n",
    "            r = reward[global_cue,global_probe,action]\n",
    "            value = values[action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            #print(global_context,global_cue,global_probe,action,'reward:',r)\n",
    "            \n",
    "            \n",
    "            performance(global_cue,global_probe,action,global_context,perf_arr)\n",
    "        ########################################\n",
    "        #print(context,cue,probe,action)\n",
    "        if trial%1000==0:\n",
    "            print('Trial:',trial,end='\\n\\n')\n",
    "            print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "            print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "            print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "            print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "            print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "            perf_arr = np.zeros((4,3))\n",
    "            print(end='\\n\\n')\n",
    "        \n",
    "    print('Trial:',trial,end='\\n\\n')\n",
    "    print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "    print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "    print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "    print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "    print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "\n",
    "    print(end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "\n",
      "                  count          performance\n",
      "AX |               28.0              100.00%\n",
      "BX |               25.0                4.00%\n",
      "AY |               23.0                0.00%\n",
      "BY |               24.0              100.00%\n",
      "\n",
      "\n",
      "Trial: 1000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24934.0              100.00%\n",
      "BX |            25047.0               99.92%\n",
      "AY |            25011.0               99.90%\n",
      "BY |            24908.0              100.00%\n",
      "\n",
      "\n",
      "Trial: 2000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24981.0              100.00%\n",
      "BX |            25039.0              100.00%\n",
      "AY |            25034.0              100.00%\n",
      "BY |            24946.0              100.00%\n",
      "\n",
      "\n",
      "Trial: 3000\n",
      "\n",
      "                  count          performance\n",
      "AX |            24885.0              100.00%\n",
      "BX |            25046.0              100.00%\n",
      "AY |            25020.0              100.00%\n",
      "BY |            25049.0              100.00%\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-285bd50e781d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# (num trials, learning rate, discount factor, lambda, temperature, decay factor, decay time steps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-71ace59fa1cf>\u001b[0m in \u001b[0;36mTD\u001b[0;34m(ntrials, lrate, gamma, td_lambda, temp, decay, time)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mglobal_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobe\u001b[0m \u001b[0;31m# used for reward function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_outer_wm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_inner_wm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0msm_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m#possible_wm = np.unique(np.array([2,signal]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TD(20000,.4,.9,.8,.1,0,0)\n",
    "# (num trials, learning rate, discount factor, lambda, temperature, decay factor, decay time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "print(x[None,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.take(x,[0,2]))\n",
    "#mask = [True,True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(x>2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            count          performance\n",
      "AX |                           12           45.000000%\n",
      "AY |                           12           45.000000%\n",
      "BX |                           12           45.000000%\n",
      "BY |                           12           45.000000%\n"
     ]
    }
   ],
   "source": [
    "count = 12\n",
    "perf = .45\n",
    "print(format('','>20s'),format('count','>12s'),format('performance','>20s'))\n",
    "print(format('AX |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('AY |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('BX |','<20s'),format(count,'>12d'),format(perf,'>20%'))\n",
    "print(format('BY |','<20s'),format(count,'>12d'),format(perf,'>20%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False False False False\n"
     ]
    }
   ],
   "source": [
    "reward(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
