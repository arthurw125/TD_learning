{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\delta = [R_{t+1} + \\gamma Q(s_{t+1}, a_{t+1})] - Q(s_t,a_t) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Q(s_t,a_t) = Q(s_t,a_t) + \\alpha\\delta $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Memory With SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from plotly.graph_objs import Scatter, Layout\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import numpy as np\n",
    "import random\n",
    "import hrr\n",
    "from plotly.graph_objs import Scatter, Layout, Surface\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TD(nstates,nepisodes,lrate,gamma,td_lambda): \n",
    "    n = 1024\n",
    "    #nstates = 50\n",
    "    nactions = 2\n",
    "    nslots = 2\n",
    "    \n",
    "    #goal for red is at 0, green at middle\n",
    "    goal = [0,nstates//2]\n",
    "    reward = np.zeros((nslots,nstates))\n",
    "    \n",
    "    # reward matrix for each context\n",
    "    for x in range(nslots):\n",
    "        reward[x,goal[x]] = 1\n",
    "    \n",
    "    # basic actions are left and right\n",
    "    states = hrr.hrrs(n,nstates)\n",
    "    actions = hrr.hrrs(n,nactions)\n",
    "    \n",
    "    # identity vector\n",
    "    hrr_i = np.zeros(n)\n",
    "    hrr_i[0] = 1\n",
    "    \n",
    "    # WorkingMemory\n",
    "    wm_slots = hrr.hrrs(n,nslots)\n",
    "    \n",
    "    # precomputed state/action/working_memory triplet\n",
    "    stateactions = hrr.oconvolve(actions,states)\n",
    "    s_a_wm = hrr.oconvolve(stateactions,wm_slots)\n",
    "    s_a_wm = np.reshape(s_a_wm,(nslots,nstates,nactions,n))\n",
    "    \n",
    "    # External representation of color\n",
    "    ncolors = 2\n",
    "    colors = hrr.hrrs(n,ncolors)\n",
    "    \n",
    "    # weight vector\n",
    "    W = hrr.hrr(n)\n",
    "    bias = 1\n",
    "\n",
    "    #lrate = 0.1\n",
    "    eligibility = np.zeros(n)\n",
    "    #gamma = 0.9\n",
    "    #td_lambda = 0.5\n",
    "    epsilon = 0.05\n",
    "    #nepisodes = 10000\n",
    "    nsteps = 100\n",
    "    \n",
    "    for episode in range(nepisodes):\n",
    "        state = random.randrange(0,nstates)\n",
    "        \n",
    "        # cue to signal context\n",
    "        color_signal = random.randrange(0,ncolors)\n",
    "        values = np.dot(s_a_wm[:,state,:,:],W) + bias\n",
    "        \n",
    "        # returns index (row,col) of max value\n",
    "        color_action = np.unravel_index(values.argmax(), values.shape)\n",
    "        color = color_action[0]\n",
    "        action = color_action[1]\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randrange(0,nactions)\n",
    "            \n",
    "        eligibility = np.zeros(n)\n",
    "        \n",
    "        for step in range(nsteps):\n",
    "            r = reward[color,state]\n",
    "            if state == goal[color]:\n",
    "                eligibility = s_a_wm[color,state,action,:] + td_lambda*gamma*eligibility\n",
    "                error = r - values[color,action]\n",
    "                W += lrate*error*eligibility\n",
    "                break\n",
    "                \n",
    "            pstate = state\n",
    "            pvalues = values\n",
    "            paction = action\n",
    "            \n",
    "            eligibility = s_a_wm[color,state,action,:] + td_lambda*gamma*eligibility\n",
    "            \n",
    "            state = ((state+np.array([-1,1]))%nstates)[action]\n",
    "            \n",
    "            values = np.dot(s_a_wm[:,state,:,:],W) + bias \n",
    "            color_action = np.unravel_index(values.argmax(), values.shape)\n",
    "            if random.random() < epsilon:\n",
    "                action = random.randrange(0,nactions)\n",
    "                \n",
    "            error = (r+gamma*values[color,action])-pvalues[color,paction]\n",
    "            W += lrate*error*eligibility\n",
    "            \n",
    "        \n",
    "    V1 = list(map(lambda x: np.dot(x,W)+bias, s_a_wm[0,:,0,:]))\n",
    "    V2 = list(map(lambda x: np.dot(x,W)+bias, s_a_wm[0,:,1,:]))\n",
    "    V3 = list(map(lambda x: np.dot(x,W)+bias, s_a_wm[1,:,0,:]))\n",
    "    V4 = list(map(lambda x: np.dot(x,W)+bias, s_a_wm[1,:,1,:]))\n",
    "    \n",
    "    plotly.offline.iplot([\n",
    "    dict(x=[x for x in range(len(V1))] , y=V1, type='scatter',name='left and red'),\n",
    "    dict(x=[x for x in range(len(V1))] , y=V2, type='scatter',name='right and red'),\n",
    "    dict(x=[x for x in range(len(V1))] , y=V3, type='scatter',name='left and green'),\n",
    "    dict(x=[x for x in range(len(V1))] , y=V4, type='scatter',name='right and green')\n",
    "    ])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TD(50,10000,.1,.9,.5)\n",
    "#inputs: nstates,nepisodes,lrate,gamma,td_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Stuff Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nslots = 3\n",
    "nstates = 5\n",
    "n = 10\n",
    "nactions = 2\n",
    "bias = 1\n",
    "# basic actions are left and right\n",
    "states = hrr.hrrs(n,nstates)\n",
    "actions = hrr.hrrs(n,nactions)\n",
    "wm_slots = hrr.hrrs(n,nslots)\n",
    "    \n",
    "stateactions = hrr.oconvolve(actions,states)\n",
    "s_a_wm = hrr.oconvolve(stateactions,wm_slots)\n",
    "stateactions = np.reshape(stateactions,(nstates,nactions,n))\n",
    "\n",
    "W = hrr.hrr(n)\n",
    "print(s_a_wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_a_wm = np.reshape(s_a_wm,(nslots,nstates,nactions,n))\n",
    "print(s_a_wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = 3\n",
    "values = np.dot(s_a_wm[:,state,:,],W) + bias\n",
    "print(values)\n",
    "#action = np.argmax(values)\n",
    "action = np.unravel_index(values.argmax(), values.shape)\n",
    "print(action)\n",
    "(nslots,nactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_a_wm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_a_wm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goal = [0,nstates//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward = np.zeros((2,3))\n",
    "print (reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_a_wm[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
