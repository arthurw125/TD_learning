{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import numpy as np\n",
    "import random\n",
    "import hrr\n",
    "import math\n",
    "from plotly.graph_objs import Scatter, Layout, Surface\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transform(error):\n",
    "    return math.copysign(1.0,error)*math.log(math.fabs(error)+1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(arr,t=1.0):\n",
    "    w = np.array(arr)\n",
    "    e = np.exp(w / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(arr_2d,restrict):\n",
    "    max_row = restrict[0]\n",
    "    max_col = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_2d[restrict[0],0]\n",
    "    for row in range(arr_2d.shape[0]):\n",
    "        if row not in restrict:\n",
    "            continue\n",
    "        for col in range(arr_2d.shape[1]):\n",
    "            if arr_2d[row,col] > max_value:\n",
    "                max_value = arr_2d[row,col]\n",
    "                max_row,max_col = row,col\n",
    "    return list((max_row,max_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax1(arr_3d,outer,inner):\n",
    "    max_row = outer[0]\n",
    "    max_col = inner[0]\n",
    "    max_x = 0\n",
    "    #max_value = arr_2d[0,0]\n",
    "    max_value = arr_3d[outer[0],inner[0],0]\n",
    "    for row in range(arr_3d.shape[0]):\n",
    "        if row not in outer:\n",
    "            continue\n",
    "        for col in range(arr_3d.shape[1]):\n",
    "            if col not in inner:\n",
    "                continue\n",
    "            for x in range(arr_3d.shape[2]):\n",
    "                if arr_3d[row,col,x] > max_value:\n",
    "                    max_value = arr_3d[row,col,x]\n",
    "                    max_row,max_col,max_x = row,col,x\n",
    "    return list((max_row,max_col,max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def context_check(outer,inner):\n",
    "    if outer == 0:\n",
    "        if inner == 0:\n",
    "            return 'AX'\n",
    "        elif inner == 1:\n",
    "            return 'AY'\n",
    "    elif outer == 1:\n",
    "        if inner == 0:\n",
    "            return 'BX'\n",
    "        elif inner == 1:\n",
    "            return 'BY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(outer,inner,action,cont,arr_2d):\n",
    "    # arr_2d[count,numcorrect,performance]\n",
    "    if context_check(outer,inner)=='AX':\n",
    "        #count1+=1\n",
    "        arr_2d[0,0]+=1\n",
    "        if action == 0 and cont == 0 or action == 1 and cont == 1:\n",
    "            #nc1 += 1\n",
    "            arr_2d[0,1]+=1\n",
    "        #AX_perf = nc1/count1\n",
    "        arr_2d[0,2] = arr_2d[0,1]/arr_2d[0,0]\n",
    "    elif context_check(outer,inner)=='BX':\n",
    "        #count2+=1\n",
    "        arr_2d[1,0]+=1\n",
    "        if action == 1:\n",
    "            #nc2 += 1\n",
    "            arr_2d[1,1]+=1\n",
    "        #BX_perf = nc2/count2\n",
    "        arr_2d[1,2] = arr_2d[1,1]/arr_2d[1,0]\n",
    "    elif context_check(outer,inner)=='AY':\n",
    "        #count3+=1\n",
    "        arr_2d[2,0]+=1\n",
    "        if action == 1:\n",
    "            #nc3 += 1\n",
    "            arr_2d[2,1]+=1\n",
    "        #AY_perf = nc3/count3\n",
    "        arr_2d[2,2] = arr_2d[2,1]/arr_2d[2,0]\n",
    "    elif context_check(outer,inner)=='BY':\n",
    "        #count4+=1\n",
    "        arr_2d[3,0]+=1\n",
    "        if action == 1 and cont == 0 or action == 0 and cont == 1:\n",
    "            #nc4 += 1\n",
    "            arr_2d[3,1]+=1\n",
    "        #BY_perf = nc4/count4\n",
    "        arr_2d[3,2] = arr_2d[3,1]/arr_2d[3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TD(ntrials,lrate,gamma,td_lambda,temp,decay,time):\n",
    "    n = 2024\n",
    "    nactions = 2 # number of actions\n",
    "    nouter_wm = 2 # number of context wm\n",
    "    ninner_wm = 2 # number of inner wm slots\n",
    "    n_context = 2 # number of context signals\n",
    "    n_cue = 2 # number of cue signals\n",
    "    n_probe = 2 # number of probe signals\n",
    "    n_cue_probe = 4\n",
    "    \n",
    "    ######## reward functions ##########\n",
    "    # reward matix, reward given at 0,0,0\n",
    "    # A-X target context\n",
    "    # 0 action => right press, 1 action => left press\n",
    "    reward1 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward1[0,0,0] = 1\n",
    "    reward1[0,1,1] = 1\n",
    "    reward1[1,0,1] = 1\n",
    "    reward1[1,1,1] = 1\n",
    "    # B-Y target context\n",
    "    reward2 = np.zeros((n_cue+1,n_probe+1,nactions))\n",
    "    reward2[0,0,1] = 1\n",
    "    reward2[0,1,1] = 1\n",
    "    reward2[1,0,1] = 1\n",
    "    reward2[1,1,0] = 1\n",
    "    # press left reward\n",
    "    reward3 = [0,0.2]\n",
    "    ####################################\n",
    "    \n",
    "    \n",
    "    ############## hrrs ###############\n",
    "    # identity vector\n",
    "    hrr_i = np.zeros(n)\n",
    "    hrr_i[0] = 1\n",
    "    \n",
    "    # L R actions hrr\n",
    "    actions = hrr.hrrs(n,nactions)\n",
    "    \n",
    "    # 1 2 context signal hrr\n",
    "    context_signal = hrr.hrrs(n,n_context)\n",
    "    context_signal = np.row_stack((context_signal,hrr_i))\n",
    "    \n",
    "    # cue signal hrr # not used\n",
    "    cue_signal = hrr.hrrs(n,n_cue)\n",
    "    cue_signal = np.row_stack((cue_signal,hrr_i))\n",
    "    \n",
    "    # probe signal hrr # not used\n",
    "    probe_signal = hrr.hrrs(n,n_probe)\n",
    "    probe_signal = np.row_stack((probe_signal,hrr_i))\n",
    "    \n",
    "    # cue and probe signals hrr\n",
    "    #cue_probe_signal = hrr.hrrs(n,n_cue_probe)\n",
    "    #cue_probe_signal = np.row_stack((cue_probe_signal,hrr_i))\n",
    "    \n",
    "    # outer working memory hrr\n",
    "    outer_wm = hrr.hrrs(n,nouter_wm)\n",
    "    outer_wm = np.row_stack((outer_wm,hrr_i))\n",
    "    \n",
    "    # inner working memory hrr\n",
    "    inner_wm = hrr.hrrs(n,ninner_wm)\n",
    "    inner_wm = np.row_stack((inner_wm,hrr_i))\n",
    "    \n",
    "    # precomputed hrr\n",
    "    #context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    #context_action_outerwm = np.reshape(context_action_outerwm,(n_context+1,nouter_wm+1,nactions,n))\n",
    "    \n",
    "    #signal_action_innerwm = hrr.oconvolve(actions,hrr.oconvolve(cue_probe_signal,inner_wm))\n",
    "    #signal_action_innerwm = np.reshape(signal_action_innerwm,(n_cue_probe+1,ninner_wm+1,nactions,n))\n",
    "    ########################################\n",
    "    #context_action_outerwm = hrr.oconvolve(actions,hrr.oconvolve(context_signal,outer_wm))\n",
    "    #signal_innerwm = hrr.oconvolve(cue_signal,hrr.oconvolve(inner_wm,probe_signal))\n",
    "    #computed = hrr.oconvolve(context_action_outerwm,signal_innerwm)\n",
    "    #computed = np.reshape(computed,(n_context+1,n_cue+1,n_probe+1,nouter_wm+1,ninner_wm+1,nactions,n))\n",
    "    \n",
    "    context_cue = hrr.oconvolve(context_signal,cue_signal)\n",
    "    probe_action = hrr.oconvolve(probe_signal,actions)\n",
    "    computed = hrr.oconvolve(context_cue,probe_action)\n",
    "    computed = np.reshape(computed, (n_context+1,n_cue+1,n_probe+1,nactions,n))\n",
    "    # weight vector and bias\n",
    "    W = hrr.hrr(n)\n",
    "    bias = 1\n",
    "    \n",
    "    # epsilon soft\n",
    "    epsilon = .01\n",
    "    \n",
    "    # temperatue for softmax\n",
    "    t = temp\n",
    "    \n",
    "    nsteps = 100\n",
    "    context = 2 # init context\n",
    "    \n",
    "    perf_arr = np.zeros((4,3))\n",
    "    \n",
    "    # lists used for displaying performance graph\n",
    "    AX_data_pts = []\n",
    "    BX_data_pts = []\n",
    "    AY_data_pts = []\n",
    "    BY_data_pts = []\n",
    "    \n",
    "    for trial in range(1,ntrials+1):\n",
    "        # absorb reward\n",
    "        if trial%50 == 0:\n",
    "            #eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            eligibility = computed[context,cue,probe,action,:] + td_lambda\n",
    "            error = r - value\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            \n",
    "            \n",
    "        context = np.random.choice([0,1],p=[.5,.5]) # choose context signal\n",
    "        \n",
    "        if context == 0:\n",
    "            reward = reward1 # use reward function 1\n",
    "        elif context == 1:\n",
    "            reward = reward2 # use reward function 2\n",
    "            \n",
    "        cue,probe = 2,2 # init with no cue/probe signal\n",
    "        current_inner_wm = 2 # init with nothing in wm\n",
    "        current_outer_wm = 2 # init with nothing in wm\n",
    "        \n",
    "        #values = np.dot(computed[context,cue,probe,:,current_inner_wm,:,:],W) + bias\n",
    "        values = np.dot(computed[context,cue,probe,:,:],W) + bias\n",
    "        #print(values.shape)\n",
    "        sm_prob = softmax(values,t)\n",
    "        #possible_wm = np.unique(np.array([context]))\n",
    "        \n",
    "        #wm_action = argmax(sm_prob,possible_wm)\n",
    "        #current_outer_wm = wm_action[0] \n",
    "        #action = wm_action[1]\n",
    "        action = np.argmax(sm_prob)\n",
    "        #print('ContexWM:',current_outer_wm)\n",
    "        #print(context,current_outer_wm,action)\n",
    "        # epsilon goes here\n",
    "        if random.random() < epsilon:\n",
    "            #current_outer_wm = random.randint(0,nouter_wm)\n",
    "            action = random.randrange(nactions)\n",
    "            \n",
    "        #current_outer_wm = 2 # empty working memory\n",
    "        #value = values[current_outer_wm,action]\n",
    "        value = values[action]\n",
    "        eligibility = np.zeros(n)\n",
    "        global_context = context # used for reward function\n",
    "        \n",
    "        \n",
    "        \n",
    "        for step in range(nsteps):\n",
    "            r = reward3[action] # # reward function, may not be needed\n",
    "            \n",
    "            # absorb reward\n",
    "            #if trial%50 == 0:\n",
    "            #    #eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            #    eligibility = computed[context,cue,probe,action,:] + td_lambda\n",
    "            #    error = r - value\n",
    "            #    W += lrate*log_transform(error)*eligibility\n",
    "            #    break\n",
    "            \n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            #eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            eligibility = computed[context,cue,probe,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = random.randint(0,1) # get cue signal\n",
    "            global_cue = cue # used for reward function\n",
    "            probe = 2\n",
    "            context = 2\n",
    "            \n",
    "            #values = np.dot(computed[context,cue,probe,current_outer_wm,:,:,:],W) + bias\n",
    "            values = np.dot(computed[context,cue,probe,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            #possible_wm = np.unique(np.array([2,cue]))\n",
    "            #wm_action = argmax(sm_prob,possible_wm)\n",
    "            #current_inner_wm = wm_action[0]\n",
    "            #action = wm_action[1]\n",
    "            # epsilon goes here\n",
    "            action = np.argmax(sm_prob)\n",
    "            if random.random() < epsilon:\n",
    "                #current_inner_wm = random.randint(0,ninner_wm) \n",
    "                action = random.randrange(nactions)\n",
    "                \n",
    "            #current_inner_wm = 2 # empty working memory\n",
    "            #value = values[current_inner_wm,action]\n",
    "            value = values[action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            \n",
    "            ###########################################\n",
    "            pvalue = value\n",
    "            paction = action\n",
    "            pcontext = context\n",
    "            pcue = cue\n",
    "            pprobe = probe\n",
    "            p_outer_wm = current_outer_wm\n",
    "            p_inner_wm = current_inner_wm\n",
    "            \n",
    "            #eligibility = computed[context,cue,probe,current_outer_wm,current_inner_wm,action,:] + td_lambda*eligibility\n",
    "            eligibility = computed[context,cue,probe,action,:] + td_lambda*eligibility\n",
    "            \n",
    "            cue = 2\n",
    "            probe = random.randint(0,1) # get probe signal\n",
    "            context = 2\n",
    "            global_probe = probe # used for reward function\n",
    "            \n",
    "            #values = np.dot(computed[context,cue,probe,current_outer_wm,current_inner_wm,:,:],W) + bias\n",
    "            values = np.dot(computed[context,cue,probe,:,:],W) + bias\n",
    "            sm_prob = softmax(values,t)\n",
    "            #possible_wm = np.unique(np.array([2,signal]))\n",
    "            #wm_action = argmax(sm_prob,possible_wm)\n",
    "            #current_inner_wm = wm_action[0]\n",
    "            #action = wm_action[1]\n",
    "            action = np.argmax(sm_prob)\n",
    "            # epsilon goes here\n",
    "            if random.random() < epsilon:\n",
    "                action = random.randrange(nactions)\n",
    "            \n",
    "            #value = values[current_inner_wm,action]\n",
    "            r = reward[global_cue,global_probe,action]\n",
    "            value = values[action]\n",
    "            error = (r+gamma*value)-pvalue\n",
    "            W += lrate*log_transform(error)*eligibility\n",
    "            #print(global_context,global_cue,global_probe,action,'reward:',r)\n",
    "            \n",
    "            \n",
    "            performance(global_cue,global_probe,action,global_context,perf_arr)\n",
    "            \n",
    "            #print(AX_data_pts)\n",
    "        ########################################\n",
    "        #print(context,cue,probe,action)\n",
    "        if trial%1000==0:\n",
    "            print('Trial:',trial,end='\\n\\n')\n",
    "            print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "            print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "            print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "            print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "            print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "            \n",
    "            AX_data_pts.append(perf_arr[0,2])\n",
    "            BX_data_pts.append(perf_arr[1,2])\n",
    "            AY_data_pts.append(perf_arr[2,2])\n",
    "            BY_data_pts.append(perf_arr[3,2])\n",
    "            \n",
    "            perf_arr = np.zeros((4,3))\n",
    "            print(end='\\n\\n')\n",
    "        \n",
    "    print('Trial:',trial,end='\\n\\n')\n",
    "    print(format('','>10s'),format('count','>12s'),format('performance','>20s'))\n",
    "    print(format('AX |','<10s'),format(perf_arr[0,0],'>12.1f'),format(perf_arr[0,2],'>20.2%'))\n",
    "    print(format('BX |','<10s'),format(perf_arr[1,0],'>12.1f'),format(perf_arr[1,2],'>20.2%'))\n",
    "    print(format('AY |','<10s'),format(perf_arr[2,0],'>12.1f'),format(perf_arr[2,2],'>20.2%'))\n",
    "    print(format('BY |','<10s'),format(perf_arr[3,0],'>12.1f'),format(perf_arr[3,2],'>20.2%'))\n",
    "\n",
    "    print(end='\\n\\n')\n",
    "    \n",
    "    V1,V2,V3,V4 = AX_data_pts,BX_data_pts,AY_data_pts,BY_data_pts\n",
    "    \n",
    "    plotly.offline.iplot([\n",
    "            dict(x=[x for x in range(len(V1))] , y=V1, type='scatter',name='AX'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V2, type='scatter',name='BX'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V3, type='scatter',name='AY'),\n",
    "            dict(x=[x for x in range(len(V1))] , y=V4, type='scatter',name='BY')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD(10000,.4,.9,.8,.1,0,0)\n",
    "# (num trials, learning rate, discount factor, lambda, temperature, decay factor, decay time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
